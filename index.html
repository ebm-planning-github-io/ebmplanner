<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="EBM, energy based models, robotics, manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <article class="post-content">
    <meta name="twitter:title" content="Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement"/>
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:image" content="./static/images/teaser.png" />
  <article class="post-content">

  <title>Energy-based Models Are Zero-Shot Planners for Compositional Scene Rearrangement</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="https://fonts.sandbox.google.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />


 <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  

  <style>
    .material-symbols-rounded {
        font-variation-settings: 'FILL' 1,
        'wght' 400,
        'GRAD' 0,
        'opsz' 48
    }


    .linkscontainer {
        max-width: 600px;
        margin: 0 auto;
    }

    .links {
        /*font-size: 5rem;*/
        /*margin: 0 -20px;*/
        display: flex;
        gap: 20px;
        justify-content: center;
        flex-wrap: wrap;
    }

    .links a span.material-symbols-rounded {
        max-width: 25px;
    }

    span.material-symbols-rounded {
        max-width: 25px;
    }

    .links a {
        display: inline-flex;
        /*flex-direction: column;*/
        align-items: center;
        text-decoration: none;
        border-radius: 5px;
        padding: 5px 7px;
        color: #f6f3f1 !important;
        font-family: 'GT Ultra', sans-serif !important;
        font-weight: 400;
        /*margin: 0 10px;*/
        transition: transform .2s;
        background-color: rgba(var(--btn-bgc), 1);
    }


    .links a:nth-child(1) {
        --btn-bgc: 237, 100, 90;
    }

    .links a:hover {
        transform: scale(1.2);
        color: #f6f3f1 !important;
    }

    .links a:active {
        transform: scale(1.3);
    }

    .links a:nth-child(2) {
        --btn-bgc: 47, 138, 196;
    }

    .links a:nth-child(3) {
        --btn-bgc: 229, 134, 6;
    }

    .links a:nth-child(4) {
        --btn-bgc: 133, 180, 51;
    }

    .links a:nth-child(5) {
        --btn-bgc: 204, 97, 176;
    }

    .links a span.material-symbols-rounded {
        margin-right: .25rem;
    }

    .links a:not(:last-child) {
        /*margin-right: 20px;*/
    }


    .links .material-symbols-rounded {
        font-size: 1.25rem;
    }


    .links i {
        font-size: 28px;
    }

    .fig {
        width: 100%;
        display: block;
        padding: 0 10px;
        margin: 0 auto;
    }

    img.arch {
        max-width: 500px;
    }

    img.blobs {
        max-width: 350px;
    }

    .teaser {
        text-align: center;
        margin-bottom: 1rem;
    }

    .teaser + section {
        margin-top: 1rem;
    }

    .teaser video {
        max-width: 600px;
        width: 100%;
    }

    img.teaser {
        max-width: 90%;
    }

    .abstract-imgs .col {
        display: flex;
        align-items: center;
    }

    .videowrapper {
        float: none;
        clear: both;
        width: 100%;
        position: relative;
        padding-bottom: 56.25%;
        padding-top: 25px;
        height: 0;
    }

    .wrapwrap {
        max-width: 800px;
        margin: 0 auto;
    }

    .videowrapper iframe {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }

    .abstract-capt {
        font-size: 0.8rem;
        display: block !important;
        text-align: center;
    }

    .latex {
        display: inline;
        font-family: 'Math', monospace;
        font-style: italic;
    }

    p {
        margin: 0 !important;
    }

    .bs-tooltip-end {
        margin-left: 3px !important;
    }

    section {
        margin: 2rem 0;
    }

    section h5 {
        margin: 1.5rem 0 0.75rem 0;
    }

    .iconbutton {
        padding: 0.1rem 0.3rem;
        display: flex;
        border: none !important;
        background-color: #4B495B !important;
        color: #f5ece5 !important;
        font-family: 'GT Ultra', sans-serif !important;
        font-weight: 400;
        text-decoration: none !important;
    }

    .iconbutton span.material-symbols-rounded {
        font-size: 1.5rem;
        /* font-weight: 700; */
    }

    .playpause span.material-symbols-rounded {
        font-variation-settings: 'wght' 700;


    }

    .iconbutton span.material-symbols-rounded:hover {
        color: #faf6f2 !important;
    }

    .iconbutton:hover, .iconbutton:focus {
        background-color: #2E2E38 !important;
        border-color: none !important;
        color: #faf6f2 !important;
    }

    .iconbutton:focus {

    }

    .iconbutton:active {
        background-color: #09090B !important;

    }

    [data-clipboard-target] {
        cursor: pointer;
    }

    [data-clipboard-target]:hover {
        color: #276FBF !important;
    }

    /* .emptyrooms {
         max-width: 80%;
     }*/

    .emptyrooms {
        display: flex;
        /*justify-content: center;*/
        align-items: flex-start;
        background-color: #f5ece5;
    }

    .playpause {
        flex-shrink: 0;
    }

    .emptyrooms img:first-child {
        width: 16.196944%;
        margin-right: 0.6%;
    }

    .emptyrooms img:last-child {
        width: 82.8862479%;
    }


    section h3 {
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
    }

    section h5, section h3 {
        justify-content: space-between;

        display: flex;
        align-items: center;
    }

    h3, h5 {
        scroll-margin-top: 25px;
        /*display: inline-block;*/
    }

    h3[data-exclude-link], h5[data-exclude-link] {
        cursor: initial;
    }

    h3 span, h5 span {
        display: inline-flex;
        align-items: center;
        cursor: pointer;
    }

    h3 span:hover, h5 span:hover {

        color: #276FBF !important;
    }

    /*
            h3[data-exclude-link]:hover, h5[data-exclude-link]:hover {
                color: initial !important;
            }*/

    .carousel {
        margin: 1rem 0;
    }

    .ltx {
        vertical-align: baseline;
    }

    .cit {
        background-color: rgba(26, 25, 31, 0.05);
        padding: 10px;
        border-radius: 5px;
        font-size: 14px;
        display: inline-block;
        margin: 0 auto;
        overflow-y: hidden;
        overflow-x: auto;
        white-space: pre-wrap;
        white-space: -moz-pre-wrap;
        white-space: -pre-wrap;
        white-space: -o-pre-wrap;
        word-wrap: break-word;
        font-family: 'Code', monospace;
    }

    .cit_cont {
        display: flex;
    }

    .video-container {
        position: relative;
    }

    /* .video-container .video-border {
         position: absolute;
         width: 100%;
         height: 100%;
         top: 0;
         left: 0;
         box-shadow: inset 0px 0px 0px 6px #f5ece5;
     }*/

    .video-container video {
        width: 100%;
        display: block;
        clip-path: inset(5px 5px);
    }

    .video-container img {
        width: 100%;
    }

    .splide > * {
        font-weight: 500;
        position: initial;
    }

    .splide__arrow {
        position: initial;
        background: none;
        /*opacity: 1;*/
        -webkit-transform: none;
        -moz-transform: none;
        -ms-transform: none;
        -o-transform: none;
        transform: none;
        font-size: 1.25rem;
        justify-content: end;
        width: 1.5em;
    }

    .splide__arrow--prev {
        justify-content: left;
    }

    .splide__slide {
        height: 0;
    }

    .splide__slide.is-visible {
        height: auto;
    }

    .move-cont {
        display: flex;
    }

    .move-cont > video {
        max-width: 100%;
    }

    .splide__pagination__page.is-active {
        background: #000;
    }

    .splide__pagination__page {
        -webkit-transition: all 0.3s;
        -moz-transition: all 0.3s;
        -ms-transition: all 0.3s;
        -o-transition: all 0.3s;
        transition: all 0.3s;
    }

    .splide__pagination {
        margin-top: 0.25rem;
    }

    .splide__pagination__page:hover {
        background: #aaa;
        transform: scale(1.2);
    }

    .splide__track_and_arrows {
        display: flex;
    }

    .splide__arrows {
        display: flex;
        align-items: center;
    }

    .styletransfer {
        display: grid;
        grid-row-gap: .5rem;
        grid-template-columns: 1fr 20px 1fr 1fr 1fr 20px 1fr 1fr 1fr;
    }

    .inversion {
        display: grid;
        /*grid-row-gap: .5rem;*/
        /*grid-template-columns: 1fr 20px 1fr 1fr 1fr 20px 1fr 1fr 1fr;*/
        grid-template-columns: 1fr 1fr 1fr 1fr 1fr;
    }

    .styletransfer img {
        max-width: 100%;
        clip-path: inset(2px 2px);
    }

    .inversion span {
        text-align: center;
    }

    .inversion img {
        max-width: 100%;
        clip-path: inset(2px 2px);
    }


    #inversion ~ .splide img {
        max-width: 100%;
        padding: 0.3rem;
    }

    .styletransfer span {
        text-align: center;
    }

    .styletransfer span:nth-child(2) {
        grid-column-start: 3;
        grid-column-end: 6;
    }

    .styletransfer span:nth-child(3) {
        grid-column-start: 7;
        grid-column-end: 10;
    }


    @media (min-width: 992px) {
        .container {
            max-width: 1050px;
        }
    }

    .inversion_subheader {
        font-weight: bold;
        text-align: center;
        margin-top: 0.5rem;
    }

    .inversion_subheader:not(:first-of-type) {
        margin-top: 0.2rem;
    }

    .inversion_subheader + .splide {
        margin: 0.2rem 0 !important;
    }

    /*
            .move-cont .video-container:nth-child(8), .move-cont .video-container:nth-child(7) {
                display: none;
            }*/

    @media (max-width: 991px) {
        /*
                    .move-cont .video-container:nth-child(5), .move-cont .video-container:nth-child(6) {
                        display: none;
                    }*/
        .move-cont > video {
            max-width: 150%;
            clip-path: inset(0 33.333333% 0 0);
        }

        header h3 {
            font-size: 1.5rem;
        }

        .cit {
            /*font-size: 12px !important;*/
        }

        .emptyrooms img:last-child {
            width: 99.6% !important;
        }

        .emptyrooms img:first-child {
            width: 19.46% !important;
            margin-right: 0.7522% !important;
        }

        .styletransfer {
            display: grid;
            grid-template-columns: 1fr 15px 1fr 1fr 15px 1fr 1fr !important;
        }

        .styletransfer img:nth-child(9n+3), .styletransfer img:nth-child(9n-1) {
            display: none;
        }

        .styletransfer span:nth-child(2) {
            grid-column-start: 3;
            grid-column-end: 5;
        }

        .styletransfer span:nth-child(3) {
            grid-column-start: 6;
            grid-column-end: 8;
        }
    }

    .author {
        padding: 0 0.6rem;
    }

    @media (max-width: 767px) {
        html, body {

            /*font-size: 16px;*/
        }

        .author {
            font-size: 18px;
        }

        .insts {
            font-size: 16px;
        }

        /*.move-cont .video-container:nth-child(4) {
            display: none;
        }*/
        .move-cont > video {
            max-width: 200%;
            clip-path: inset(0 50% 0 0);
        }

        .inversion *:nth-child(5n+2) {
            display: none;
        }

        .inversion {
            grid-template-columns: 1fr 1fr 1fr 1fr;
        }

        .emptyrooms img:last-child {
            width: 124.477307% !important;
        }

        .emptyrooms img:first-child {
            width: 24.3243243% !important;
            margin-right: 0.9% !important;
        }

        .styletransfer {
            display: grid;
            grid-template-columns: 1fr 10px 1fr 10px 1fr !important;
        }

        .styletransfer img:nth-child(9n+2), .styletransfer img:nth-child(9n-2) {
            display: none;
        }

        .styletransfer span:nth-child(2) {
            grid-column-start: 3;
            grid-column-end: 4;
        }

        .styletransfer span:nth-child(3) {
            grid-column-start: 5;
            grid-column-end: 6;
        }
    }

    @media (max-width: 540px) {
        .links a span.material-symbols-rounded {
            max-width: 20px;
        }

        .links {
            gap: 12px;
        }
    }

    @media (max-width: 510px) {
        /*
                    .move-cont .video-container:nth-child(3) {
                        display: none;
                    }*/
        .move-cont > video {
            max-width: 300%;
            clip-path: inset(0 66.6666666% 0 0);
        }


        .inversion {
            grid-template-columns: 1fr 1fr;
        }

        .inversion span:nth-child(n+4) {
            grid-row: 3;
        }

        .links .material-symbols-rounded {
            /*display: none;*/
            font-size: 1rem;
        }

        .links a span.material-symbols-rounded {
            max-width: 18px;
        }

    }

    @media (max-width: 399px) {

    }

    @media (max-width: 380px) {
        /*.links .material-symbols-rounded {*/
        /*    display: none;*/
        /*    padding: 5px 10px;*/
        /*    !*font-size: 1rem;*!*/
        /*}*/
    }

    @media (max-width: 575px) {

        img.blobs {
            max-width: 300px;
        }

        .emptyrooms img:last-child {
            width: 165.941536% !important;
        }

        .emptyrooms img:first-child {
            width: 32.4269205% !important;
            margin-right: 1.15% !important;
        }
    }

    @media (min-width: 768px) {
        .abstract-imgs .col-md-7 {
            border-right: 1px solid #1f1e1d;
        }

        img.arch, img.blobs {
            max-width: 600px;
        }

    }


</style>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://nickgkan.github.io/">Nikolaos Gkanatsios</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://ayushjain1144.github.io/">Ayush Jain</a><sup>*</sup>,</span>
              <span class="author-block">
              <a href="https://www.zhou-xian.com/">Zhou Xian</a>,
            </span>
            <span class="author-block">
              <a href="https://github.com/YunchuZhang">Yunchu Zhang</a>,
            </span>
            <span class="author-block">
              <a href="http://www.cs.cmu.edu/~cga/">Christopher G. Atkeson</a>
            </span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a>
            </span>
            
          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University,</span>
          </div>
          
          <div class="is-size-5 contribution">
            <span class="appear"><a href="https://roboticsconference.org/">RSS 2023</a></span>
          </div>

          <div class="is-size-5 contribution">
            <span class="contribution"><sup>*</sup>Equal Contribution</span>
          </div><br> 

          <!-- <table align=center width=700px>
            <tr>
              <td align=center width=100px><center><span style="font-size:28px"><a href="https://arxiv.org/abs/2304.14391">[Paper]</a></span></center></td>
              <td align=center width=100px><center><span style="font-size:28px"><a href="https://github.com/nickgkan/butd_detr">[Code]</a></span></center></td>
          <tr/>
        </table> -->

        <div class="linkscontainer">
          <div class="links mt-4">
          <a href="https://arxiv.org/abs/2304.14391" target="_blank"><span class="material-symbols-rounded">
          description
          </span><span>Paper</span></a>
          <a href="https://github.com/ayushjain1144/ebmplanner" target="_blank"><span class="material-symbols-rounded">
          code
          </span><span>Code</span></a>
          <!-- <a href="#results"><span class="material-symbols-rounded">
          science
          </span><span>Results</span></a> -->
          </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene-rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then re-locate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model can execute highly compositional instructions zero-shot in simulation and in the real world. It outperforms language-to-action reactive policies and Large Language Model planners by a large margin, especially for long instructions that involve compositions of multiple spatial concepts.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://drive.google.com/file/d/1ET4QyJ8WsqHwDz6PxgD-EuhZoq5FdGFl/view" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Method </h2>
        
        <div class="col-md-8 col-md-offset-2">
                <figure>
                    <img src="./static/images/model.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <!-- <figcaption class="figure-caption text-center" style="font-size: 14px;">
                        <b>Fig. 5.</b> The ReferIt3DNet neural listener.
                    </figcaption> -->
                </figure>
    </div>
        
        <div class="content has-text-justified">
          <p>
            Given an image and a language instruction, a semantic parser maps the language into a set of energy functions (BinaryEBM, MultiAryEBM), one for each spatial predicate in the instruction, and calls  to an open-vocabulary visual language grounder (VLMGround) to localize the object arguments of each energy function mentioned in the instruction, here "fruits" and "plate". Gradient descent on the sum of energy functions with respect to object spatial coordinates generates the goal scene configuration. Vision-based neural policies  condition on the predicted pick and place visual image crops and predict accurate pick and place locations to manipulate the objects. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-max-desktop">
          <h2 class="title is-3">Real-world Results</h2>
          <div class="content has-text-justified">
            <p>
                Our model is trained in simulation and can generalize to the real world without 
                any real-world training or adaptation thanks to the open-vocabulary detector trained on real-world images, as well 
                as the object abstractions in the predicate EBMs and low-level policy modules. 
                In addition to robot execution, we also show all intermediate visual grounding outputs and energy minimization for goal generation.
            </p>
          </div>
        </div>
      </div>
    </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/real/circle0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/real/circle_inside_a_plate0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/real/composition_group0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/real/composition_single0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/real/line0.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-max-desktop">
          <h2 class="title is-3">Simulation Results</h2>
          <div class="content has-text-justified">
            <p>
                Videos 1-4 (left to right) demonstrate our zero-shot generalization to compositions of known concepts. 
                Videos 5 and 6 show multi-ary concepts. 
                Videos 7 and 8 showcase closed-loop execution. Our model fails to solve the task in the first attempt, but then re-detects the referred objects, 
                compares their location to the goal location (the output of the EBM planner) and re-locates them to complete the task.
            </p>
          </div>
        </div>
      </div>
    </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/composition_single_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/composition_group_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/composition_group_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/composition_single_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/circle_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/line_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/good_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sim/good_2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-max-desktop">
          <h2 class="title is-3">Examples of Energy Optimization</h2>
          <div class="content has-text-justified">
            <p>
                (Left to right) Examples 1-5 show training concepts, both binary and multi-ary. 
                Examples 6-8 show zero-shot generalization to compositions of training concepts. 
                Example 9 shows a task that involves pose optimization. 
                Examples 10 and 11 display our EBMs' ability to learn 3D concepts and generalize zero-shot to compositions of them.
            </p>
          </div>
        </div>
      </div>
    </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="carousel-item">
            <img src="./static/videos/ebm/above.gif">
            <div class="carousel-caption has-text-centered">
                <p>Cyan above blue</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/inside.gif">
            <div class="carousel-caption has-text-centered">
                <p>Cyan inside blue</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/left.gif">
            <div class="carousel-caption has-text-centered">
                <p>Cyan left of blue</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/below.gif">
            <div class="carousel-caption has-text-centered">
                <p>Cyan below blue</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/circle.gif">
            <div class="carousel-caption has-text-centered">
                <p>Circle</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/circle_in_plate.gif">
            <div class="carousel-caption has-text-centered">
                <p>(Zero-Shot) Circle inside plate</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/comp.gif">
            <div class="carousel-caption has-text-centered">
                <p>(Zero-Shot) Green inside blue and blue right of red and cyan left of blue and red above box and blue below yellow</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/comp2.gif">
            <div class="carousel-caption has-text-centered">
                <p>(Zero-Shot) Blue left of green and blue right of red and cyan inside blue and red below magenta and blue above yellow</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/racer.gif">
            <div class="carousel-caption has-text-centered">
                <p>(Pose) A circle of triangles each pointing to the next</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/ontop.gif">
            <div class="carousel-caption has-text-centered">
                <p>(3D) Red on top of green</p>
            </div>
        </div>
        <div class="carousel-item">
            <img src="./static/videos/ebm/stack.gif">
            <div class="carousel-caption has-text-centered">
                <p>(3D+Zero-Shot) Stack cyan on top of red on top of green on top of blue</p>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Quantitative Results </h2>
       
        <div class="content has-text-justified">
          <p>
            SREM outperforms state-of-the-art Large Language Model planners on highly compositional tasks. 
          </p>
        </div>

        <div class="col-md-8 col-md-offset-2">
                <figure>
                    <img src="./static/images/performance.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <!-- <figcaption class="figure-caption text-center" style="font-size: 14px;">
                        <b>Fig. 5.</b> The ReferIt3DNet neural listener.
                    </figcaption> -->
                </figure>
    </div>
    <!-- <div class="content has-text-justified">
      <p>
        BUTD-DETR works on 2D domain as well achieving comparable performance to MDETR, while converging twice as fast, due to architectural optimizations such as deformable attention. With minimal changes, our model works both on 3D and 2D, thus taking a step towards unifying grounding models for 2D and 3D.
      </p>
    </div> -->
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
     Abstract. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Qualitative Results: 3D </h2>
        
        <div class="col-md-8 col-md-offset-2">
                <figure>
                    <img src="./static/images/qual.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption class="figure-caption text-center" style="font-size: 24px;">
                    <span style="color: #0000a0">Blue boxes</span>
 refer to our predictions,
  <span style="color: #00ff00">green boxes</span> 
                           refer to ground truths.
                    </figcaption>
                </figure>
    </div>
        
      </div>
    </div>
  </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Qualitative Results: 2D </h2>
        
        <div class="col-md-8 col-md-offset-2">
                <figure>
                    <img src="./static/images/qual_2d.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption class="figure-caption text-center" style="font-size: 24px;">
                    <span style="color: #ff0000">Red boxes</span>
 refer to our predictions,
  <span style="color: #00ff00">green boxes</span> 
                           refer to ground truths.
                    </figcaption>
                </figure>
    </div>
        
      </div>
    </div>
  </div>
</section> -->



<section class="section" id="BibTeX1">
<div class="container is-max-desktop content">
  <h2 class="title" align="center">Paper and Bibtex</h2>

    <span class="gg">
      <a href="https://arxiv.org/abs/2304.14391"><img style="width:200px" src="static/images/thumbnail.png" align="left"/> </a>
    
   
      <!-- <a href="htps://arxiv.org/abs/2112.08879">[Paper]</a> -->
    </span>
    <pre><code>
      @inproceedings{gkanatsios2023energybased,
        title={{Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement}},
        author={Gkanatsios, Nikolaos and Jain, Ayush and Xian, Zhou and Zhang, Yunchu and Atkeson, Christopher and Fragkiadaki, Katerina},
        booktitle={Robotics: Science and Systems},
        year={2023}
      }
}
    </code></pre>

    <!-- <span class="author-block">
      <a href="https://arxiv.org/abs/2112.08879"><img style="width:400px" src="static/images/thumbnail.png"/></a> 
      <a href="https://arxiv.org/abs/2112.08879">[Paper]</a>
    </span> -->

  <!-- <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br/><span style="font-size:6px;">&nbsp;<br/></span> <span style="font-size:15pt">Jain, A., Gkanatsios, N., Mediratta, I. and Fragkiadaki, K. (2021). <br>
      Bottom Up Top Down Detection Transformers for Language Grounding in Images and Point Clouds
      <br> <em> ArXiv, abs/2112.08879.</em> </span></p> -->
  <!-- <p style="margin-top:20px;"></p> -->     
  </div>
</section>
<br><hr>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2304.14391">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/ayushjain1144/ebmplanner" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Source code of this website is borrowed from  <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies template</a>.
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
